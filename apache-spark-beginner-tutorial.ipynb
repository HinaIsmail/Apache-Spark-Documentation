{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Apache Spark - Beginner Tutorial\n",
    "\n",
    "Firstly, Thank you for checking this tutorial notebook. By now you must have read a lot about Apache Spark and its ML Library.So, I won't bore you with the introduction to Apache-Spark or even the library details. We shall move straight to the interesting stuff i.e. coding.\n",
    "\n",
    "In this tuorial notebook we will try to compare some of the Apache Spark's Classification Algorithms in an easy way to make predictions. And since this is a beginner's tutorial, we will use the Iris Flower Dataset aka the beginner's dataset in machine learning.\n",
    "\n",
    "**A quick summary:**\n",
    "\n",
    "* Import Libraries\n",
    "* Build Spark Session\n",
    "* Data Load\n",
    "* Data Exploration & Preparation\n",
    "* Feature Engineering\n",
    "* Data Scaling\n",
    "* Data Split\n",
    "* Build, Train & Evaluate Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install Apache Spark\n",
    "!pip install pyspark --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#Generic Libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "#Apache Spark Libraries\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Apache Spark ML CLassifier Libraries\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier,NaiveBayes\n",
    "\n",
    "#Apache Spark Evaluation Library\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#Apache Spark Features libraries\n",
    "from pyspark.ml.feature import StandardScaler,StringIndexer, VectorAssembler, VectorIndexer, OneHotEncoder\n",
    "\n",
    "#Apache Spark Pipelin Library\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Apache Spark `DenseVector`\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "#Data Split Libraries\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Tabulating Data\n",
    "from tabulate import tabulate\n",
    "\n",
    "#Garbage\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Build Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Spark Session\n",
    "spark = (SparkSession.builder\n",
    "                  .appName('Apache Spark Beginner Tutorial')\n",
    "                  .config(\"spark.executor.memory\", \"1G\")\n",
    "                  .config(\"spark.executor.cores\",\"4\")\n",
    "                  .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[sepal_length: double, sepal_width: double, petal_length: double, petal_width: double, species: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = '../input/iris-dataset/iris.csv'\n",
    "\n",
    "data = spark.read.format(\"csv\") \\\n",
    "       .option(\"header\", \"true\") \\\n",
    "       .option(\"inferSchema\",\"true\")\\\n",
    "       .load(url) \n",
    "\n",
    "data.cache() #for faster re-use"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Data Exploration & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total records \n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Data Type\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display records\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|   species|count|\n",
      "+----------+-----+\n",
      "| virginica|   50|\n",
      "|versicolor|   50|\n",
      "|    setosa|   50|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Records per Species\n",
    "data.groupBy('species').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "|summary|      sepal_length|        sepal_width|      petal_length|       petal_width|  species|\n",
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "|  count|               150|                150|               150|               150|      150|\n",
      "|   mean| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|     null|\n",
      "| stddev|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|     null|\n",
      "|    min|               4.3|                2.0|               1.0|               0.1|   setosa|\n",
      "|    max|               7.9|                4.4|               6.9|               2.5|virginica|\n",
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Dataset Summary Stats\n",
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Inorder for our model to make predictions the Species aka Label column should be a numerical value (models don't like string!). To achieve this we shall use String Indexing on the Species columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|species_indx|\n",
      "+------------+-----------+------------+-----------+-------+------------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|         0.0|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|         0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|         0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|         0.0|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|         0.0|\n",
      "+------------+-----------+------------+-----------+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#String Indexing the Species column\n",
    "SIndexer = StringIndexer(inputCol='species', outputCol='species_indx')\n",
    "data = SIndexer.fit(data).transform(data)\n",
    "\n",
    "#Inspect the dataset\n",
    "data.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "The Spark model needs two columns: “label” and “features” and we are not going to do much feature engineering because we want to focus on the mechanics of training the model in Spark. \n",
    "\n",
    "So, creating a seperate dataframe with re-ordered columns, then defining an input data using Dense Vector. A Dense Vector is a local vector that is backed by a double array that represents its entry values. In other words, it's used to store arrays of values for use in PySpark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----------+------------+-----------+\n",
      "|species_indx|sepal_length|sepal_width|petal_length|petal_width|\n",
      "+------------+------------+-----------+------------+-----------+\n",
      "|         0.0|         5.1|        3.5|         1.4|        0.2|\n",
      "|         0.0|         4.9|        3.0|         1.4|        0.2|\n",
      "|         0.0|         4.7|        3.2|         1.3|        0.2|\n",
      "|         0.0|         4.6|        3.1|         1.5|        0.2|\n",
      "|         0.0|         5.0|        3.6|         1.4|        0.2|\n",
      "+------------+------------+-----------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating a seperate dataframe with re-ordered columns\n",
    "df = data.select(\"species_indx\",\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\")\n",
    "\n",
    "#Inspect the dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**Note:** Observe that the species column which is our label (aka Target) is now at beginning of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the `input_data` as Dense Vector\n",
    "input_data = df.rdd.map(lambda x: (x[0], DenseVector(x[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**Note:** Observe the definition of the Dense Vector. So,when we create a new indexed dataframe(below) the machine understands that the first column is a Label (Target) and the remaining columns are Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new Indexed Dataframe\n",
    "df_indx = spark.createDataFrame(input_data, [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|label|         features|\n",
      "+-----+-----------------+\n",
      "|  0.0|[5.1,3.5,1.4,0.2]|\n",
      "|  0.0|[4.9,3.0,1.4,0.2]|\n",
      "|  0.0|[4.7,3.2,1.3,0.2]|\n",
      "|  0.0|[4.6,3.1,1.5,0.2]|\n",
      "|  0.0|[5.0,3.6,1.4,0.2]|\n",
      "+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the indexed dataframe\n",
    "df_indx.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Data Scaling\n",
    "\n",
    "This is also known as Feature Scaling. It is a method of normalizing the features of the data. Scaling can make a difference between a weak machine learning model and a better one. \n",
    "\n",
    "In this tutorial we will use a Standard Scaler to scale our feature data. Apache Spark has a Standard Scaler library to do the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Standard Scaler\n",
    "stdScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "#Fit the Standard Scaler to the indexed Dataframe\n",
    "scaler = stdScaler.fit(df_indx)\n",
    "\n",
    "#Transform the dataframe\n",
    "df_scaled =scaler.transform(df_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+--------------------+\n",
      "|label|         features|     features_scaled|\n",
      "+-----+-----------------+--------------------+\n",
      "|  0.0|[5.1,3.5,1.4,0.2]|[6.15892840883878...|\n",
      "|  0.0|[4.9,3.0,1.4,0.2]|[5.9174018045706,...|\n",
      "|  0.0|[4.7,3.2,1.3,0.2]|[5.67587520030241...|\n",
      "|  0.0|[4.6,3.1,1.5,0.2]|[5.55511189816831...|\n",
      "|  0.0|[5.0,3.6,1.4,0.2]|[6.03816510670469...|\n",
      "+-----+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Viewing the Scaled Data\n",
    "df_scaled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the Features column\n",
    "df_scaled = df_scaled.drop(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Data Split\n",
    "\n",
    "Just like always, before building a model we shall split our scaled dataset into training & test sets. \n",
    "Training Dataset = 90%\n",
    "Test Dataset = 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df_scaled.randomSplit([0.9, 0.1], seed = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|     features_scaled|\n",
      "+-----+--------------------+\n",
      "|  0.0|[5.19282199176603...|\n",
      "|  0.0|[5.31358529390013...|\n",
      "|  0.0|[5.31358529390013...|\n",
      "|  0.0|[5.31358529390013...|\n",
      "|  0.0|[5.43434859603422...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inspect Training Data\n",
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Build, Train & Evaluate Model\n",
    "\n",
    "In this step we will create multiple models, train them on our scaled dataset and then compare their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['Decision Tree','Random Forest','Naive Bayes']\n",
    "model_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Decision Tree Classifier --\n",
    "\n",
    "dtc = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features_scaled\")          #instantiate the model\n",
    "dtc_model = dtc.fit(train_data)                                                        #train the model\n",
    "dtc_pred = dtc_model.transform(test_data)                                              #model predictions\n",
    "\n",
    "#Evaluate the Model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "dtc_acc = evaluator.evaluate(dtc_pred)\n",
    "#print(\"Decision Tree Classifier Accuracy =\", '{:.2%}'.format(dtc_acc))\n",
    "model_results.extend([[model[0],'{:.2%}'.format(dtc_acc)]])                               #appending to list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Random Forest Classifier --\n",
    "\n",
    "rfc = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features_scaled\", numTrees=10)          #instantiate the model\n",
    "rfc_model = rfc.fit(train_data)                                                                     #train the model\n",
    "rfc_pred = rfc_model.transform(test_data)                                                           #model predictions\n",
    "\n",
    "#Evaluate the Model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "rfc_acc = evaluator.evaluate(rfc_pred)\n",
    "#print(\"Random Forest Classifier Accuracy =\", '{:.2%}'.format(rfc_acc))\n",
    "model_results.extend([[model[1],'{:.2%}'.format(rfc_acc)]])                                            #appending to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Naive Bayes Classifier --\n",
    "\n",
    "nbc = NaiveBayes(smoothing=1.0,modelType=\"multinomial\", labelCol=\"label\",featuresCol=\"features_scaled\")    #instantiate the model\n",
    "nbc_model = nbc.fit(train_data)                                                                          #train the model\n",
    "nbc_pred = nbc_model.transform(test_data)                                                                #model predictions\n",
    "\n",
    "#Evaluate the Model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "nbc_acc = evaluator.evaluate(nbc_pred)\n",
    "#print(\"Naive Bayes Accuracy =\", '{:.2%}'.format(nbc_acc))\n",
    "model_results.extend([[model[2],'{:.2%}'.format(nbc_acc)]])                                            #appending to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freeing memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Tabulating the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Models    Accuracy\n",
      "-------------------  ----------\n",
      "Decision Tree        90.91%\n",
      "Random Forest        100.00%\n",
      "Naive Bayes          100.00%\n"
     ]
    }
   ],
   "source": [
    "print (tabulate(model_results, headers=[\"Classifier Models\", \"Accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "![](https://www.appreciationatwork.com/wp-content/uploads/2018/01/thank-you.jpg)\n",
    "\n",
    "I hope this tutorial was helpful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
